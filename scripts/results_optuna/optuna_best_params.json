{
  "neurons_layer_1": 32,
  "neurons_layer_2": 48,
  "neurons_layer_3": 16,
  "neurons_layer_4": 4,
  "dropout_rate": 0.4,
  "l2_reg": 0.002063680713812367,
  "extended_dropout": true,
  "activation_function": "leaky_relu",
  "optimizer_type": "adam",
  "learning_rate": 0.00033732651610264363,
  "batch_size": 32
}